{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "XV2D5GGrZS_x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XV2D5GGrZS_x",
    "outputId": "8dbce3a4-07a1-4c41-98d0-b5a4d7458c8a"
   },
   "outputs": [],
   "source": [
    "# %autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "kZwl8flArmz7",
   "metadata": {
    "id": "kZwl8flArmz7"
   },
   "outputs": [],
   "source": [
    "# !pip install bitsandbytes\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40501a7-997c-43ee-ba08-7677af194c5d",
   "metadata": {
    "id": "b40501a7-997c-43ee-ba08-7677af194c5d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    "    pipeline\n",
    ")\n",
    "import bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MBkhEiFq8K1M",
   "metadata": {
    "id": "MBkhEiFq8K1M"
   },
   "source": [
    "#### Load the base Model to be finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a580a73-68f3-4d58-bd3f-3ceadcba0401",
   "metadata": {
    "id": "8a580a73-68f3-4d58-bd3f-3ceadcba0401"
   },
   "outputs": [],
   "source": [
    "model_id=\"FacebookAI/roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00936cd1-9fd4-4662-9733-2d3976167899",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00936cd1-9fd4-4662-9733-2d3976167899",
    "outputId": "9b893e8b-ea1b-4511-a737-caf82b74b211"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "classifier= pipeline('text-classification', model=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6Hce5hoH8S3e",
   "metadata": {
    "id": "6Hce5hoH8S3e"
   },
   "source": [
    "Syntax to run model\n",
    "No meaningful output as of now as this is the base model and there are no lables like \"POSITIVE\" and \"NEGATIVE\" that it has inbuilt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6663f0b9-d2dc-46d9-bc62-60cd6ceab00e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6663f0b9-d2dc-46d9-bc62-60cd6ceab00e",
    "outputId": "bad302c9-e457-4d19-dc91-6474f2c25218"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.5334505438804626}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"HELLO!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4LVuJuC5Yp_K",
   "metadata": {
    "id": "4LVuJuC5Yp_K"
   },
   "source": [
    "## **CREATING** **DATASET**\n",
    "#### TODO: Get a much larger and comprehensive dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7d8238-3a00-4fc3-aa2a-3fb5c2b5b7d4",
   "metadata": {
    "id": "4e7d8238-3a00-4fc3-aa2a-3fb5c2b5b7d4"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "# TODO -  generate large synthetic data in future to prevent overfitting\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"./data/jira_scrum_role_dataset.csv\")\n",
    "df2 = pd.read_csv(\"./data/role_classification_dataset_long.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4444787e-290a-4cde-ba70-debcbdf58723",
   "metadata": {
    "id": "4444787e-290a-4cde-ba70-debcbdf58723"
   },
   "outputs": [],
   "source": [
    "#concat the dataset into a single entity with mixing the rows\n",
    "dataset = pd.concat([df1,df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4910a2c9-e300-43dd-a78e-ea2c91e3c6bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "4910a2c9-e300-43dd-a78e-ea2c91e3c6bb",
    "outputId": "d2148bb4-dc82-4a8c-9c0f-425d3e837873"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Implement responsive UI using React: Implement...</td>\n",
       "      <td>FrontEndEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Add new components to the dashboard: Add new c...</td>\n",
       "      <td>FrontEndEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add new components to the dashboard: Add new c...</td>\n",
       "      <td>FrontEndEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fix CSS styling issues for mobile view: Fix CS...</td>\n",
       "      <td>FrontEndEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Add new components to the dashboard: Add new c...</td>\n",
       "      <td>FrontEndEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>Scale bleeding-edge web-readiness. Develop new...</td>\n",
       "      <td>FrontEndEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>Revolutionize scalable solutions. Configure al...</td>\n",
       "      <td>DevOpsEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>Syndicate customized paradigms. Improve access...</td>\n",
       "      <td>FrontEndEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>Incubate mission-critical architectures. Fix b...</td>\n",
       "      <td>BackendEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>Aggregate vertical communities. Optimize the S...</td>\n",
       "      <td>BackendEngineer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description              role\n",
       "0     Implement responsive UI using React: Implement...  FrontEndEngineer\n",
       "1     Add new components to the dashboard: Add new c...  FrontEndEngineer\n",
       "2     Add new components to the dashboard: Add new c...  FrontEndEngineer\n",
       "3     Fix CSS styling issues for mobile view: Fix CS...  FrontEndEngineer\n",
       "4     Add new components to the dashboard: Add new c...  FrontEndEngineer\n",
       "...                                                 ...               ...\n",
       "6995  Scale bleeding-edge web-readiness. Develop new...  FrontEndEngineer\n",
       "6996  Revolutionize scalable solutions. Configure al...    DevOpsEngineer\n",
       "6997  Syndicate customized paradigms. Improve access...  FrontEndEngineer\n",
       "6998  Incubate mission-critical architectures. Fix b...   BackendEngineer\n",
       "6999  Aggregate vertical communities. Optimize the S...   BackendEngineer\n",
       "\n",
       "[7000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73d311f-03e9-4399-a705-063fddcc97a0",
   "metadata": {
    "id": "f73d311f-03e9-4399-a705-063fddcc97a0"
   },
   "outputs": [],
   "source": [
    "dataset_y = dataset['role']\n",
    "dataset.drop(['role'], inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f394b430-e492-49ca-bb71-472e86cf3ce8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "f394b430-e492-49ca-bb71-472e86cf3ce8",
    "outputId": "9a0c5b09-bca0-470f-8cfe-6ba337e9bfaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       FrontEndEngineer\n",
       "1       FrontEndEngineer\n",
       "2       FrontEndEngineer\n",
       "3       FrontEndEngineer\n",
       "4       FrontEndEngineer\n",
       "              ...       \n",
       "6995    FrontEndEngineer\n",
       "6996      DevOpsEngineer\n",
       "6997    FrontEndEngineer\n",
       "6998     BackendEngineer\n",
       "6999     BackendEngineer\n",
       "Name: role, Length: 7000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9fb2d7c-da32-41b6-b5a9-cebf1b515fd6",
   "metadata": {
    "id": "d9fb2d7c-da32-41b6-b5a9-cebf1b515fd6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, dataset_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71c16c7-3c28-4253-8c23-e164aa59d694",
   "metadata": {
    "id": "a71c16c7-3c28-4253-8c23-e164aa59d694"
   },
   "source": [
    "## Preprocessing\n",
    "- Clean the data (if necessary)\n",
    "- Need to tokenize the inputs to feed into model\n",
    "- Need to label encode the output to multiple classes for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4907db25-2368-4cae-89ed-8de97a707738",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4907db25-2368-4cae-89ed-8de97a707738",
    "outputId": "c45031e9-4bb7-4d6f-df4d-02d3d622e687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BackendEngineer', 'FrontEndEngineer', 'CloudEngineer',\n",
       "       'DevOpsEngineer', 'AIEngineer', 'DatabaseDesignEngineer'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = y_train.unique()\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VRzolbIeY0dU",
   "metadata": {
    "id": "VRzolbIeY0dU"
   },
   "source": [
    "# **TOKENIZING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UMl_RM_59J47",
   "metadata": {
    "id": "UMl_RM_59J47"
   },
   "source": [
    "##### We tokenize input data using the existing tokenizer for the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "308b0a4d-a645-4129-a752-2dc0286c98f9",
   "metadata": {
    "id": "308b0a4d-a645-4129-a752-2dc0286c98f9"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e04fb35e-6b6e-4fed-a30f-da6a818dad4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "e04fb35e-6b6e-4fed-a30f-da6a818dad4b",
    "outputId": "622abd4f-40be-4d55-a43f-b503b04f1869"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>Integrate third-party payment gateway: Integra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>Envisioneer front-end e-services. Improve acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>Optimize cloud resource usage: Optimize cloud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>Configure Docker containers for services: Conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6914</th>\n",
       "      <td>Brand enterprise users. Develop new React comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>Migrate services to AWS Lambda: Migrate servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>Evaluate model performance on validation set: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>Set up ML pipeline for training and inference:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>Fine-tune GPT model for text generation: Fine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Refactor frontend state management: Refactor f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5600 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description\n",
       "1032  Integrate third-party payment gateway: Integra...\n",
       "6339  Envisioneer front-end e-services. Improve acce...\n",
       "3886  Optimize cloud resource usage: Optimize cloud ...\n",
       "2653  Configure Docker containers for services: Conf...\n",
       "6914  Brand enterprise users. Develop new React comp...\n",
       "...                                                 ...\n",
       "3772  Migrate services to AWS Lambda: Migrate servic...\n",
       "5191  Evaluate model performance on validation set: ...\n",
       "5226  Set up ML pipeline for training and inference:...\n",
       "5390  Fine-tune GPT model for text generation: Fine-...\n",
       "860   Refactor frontend state management: Refactor f...\n",
       "\n",
       "[5600 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Gr_lcpigcwhK",
   "metadata": {
    "id": "Gr_lcpigcwhK"
   },
   "outputs": [],
   "source": [
    "# Tokenising the train and test inputs to finetune the model\n",
    "train_encodings = tokenizer(list(X_train['description']), padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "test_encodings = tokenizer(list(X_test['description']), padding=True, truncation=True, max_length=256, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dRjM-Owgh0Vk",
   "metadata": {
    "id": "dRjM-Owgh0Vk"
   },
   "source": [
    "#### Since the task is classification, we use a Label Encoder to convert the roles into numeric representations so simplify the process of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "C_E8rA-TetuK",
   "metadata": {
    "id": "C_E8rA-TetuK"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_enc = torch.tensor(label_encoder.fit_transform(y_train))\n",
    "y_test_enc = torch.tensor(label_encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "qfiEfUZzfzll",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfiEfUZzfzll",
    "outputId": "86b46f44-183e-488a-f0a8-326231d8280c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 5, 2,  ..., 0, 0, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GgY5rkRIgY_P",
   "metadata": {
    "id": "GgY5rkRIgY_P"
   },
   "source": [
    "### Create a Role to Index and Role to Index Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6NSQykCgf7FI",
   "metadata": {
    "id": "6NSQykCgf7FI"
   },
   "outputs": [],
   "source": [
    "# RoleToIndex = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_).astype(float)))\n",
    "# IndexToRole = dict(zip(label_encoder.transform(label_encoder.classes_).astype(float), label_encoder.classes_))\n",
    "IndexToRole = {int(i): role for i, role in zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_)}\n",
    "RoleToIndex = {role: int(i) for role, i in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0Xd0WwSrgW8W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Xd0WwSrgW8W",
    "outputId": "74eb8b9e-0d06-4bd3-8751-dd0913c7f617"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'AIEngineer': 0,\n",
       "  'BackendEngineer': 1,\n",
       "  'CloudEngineer': 2,\n",
       "  'DatabaseDesignEngineer': 3,\n",
       "  'DevOpsEngineer': 4,\n",
       "  'FrontEndEngineer': 5},\n",
       " {0: 'AIEngineer',\n",
       "  1: 'BackendEngineer',\n",
       "  2: 'CloudEngineer',\n",
       "  3: 'DatabaseDesignEngineer',\n",
       "  4: 'DevOpsEngineer',\n",
       "  5: 'FrontEndEngineer'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RoleToIndex, IndexToRole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nMmir0X2lPzt",
   "metadata": {
    "id": "nMmir0X2lPzt"
   },
   "source": [
    "The Roberta Base Model does not come with any predefined labels like \"POSITIVE\" \"NEGATIVE\". This is becase it has not been trained for any specific purpose.\n",
    "\n",
    "We can define our own labels and can finetune the model on those classes.\n",
    "\n",
    "The following cell updates the base model with custom labels define above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62Drqx0Ik6SM",
   "metadata": {
    "id": "62Drqx0Ik6SM"
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_id)\n",
    "config.update({\"id2label\": IndexToRole})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "N1yUgLyYlTSn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N1yUgLyYlTSn",
    "outputId": "6f864ae5-b9c2-4402-dd7c-a9217bab1768"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_id, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn002umk-On5",
   "metadata": {
    "id": "nn002umk-On5"
   },
   "source": [
    "Converting the dataset to the standard format required for the training and finetuning of Roberta Models using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "o8EdpdjYoH9r",
   "metadata": {
    "id": "o8EdpdjYoH9r"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "class RoleDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = RoleDataset(train_encodings, y_train_enc)\n",
    "test_dataset = RoleDataset(test_encodings, y_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CoTzwHxg-kQD",
   "metadata": {
    "id": "CoTzwHxg-kQD"
   },
   "source": [
    "## **FINETUNING** **BEGINS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kRHPltNC-oF0",
   "metadata": {
    "id": "kRHPltNC-oF0"
   },
   "source": [
    "We will save multiple versions of the model in a directory to and pick the model with the least loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_qNMZw81qxCB",
   "metadata": {
    "id": "_qNMZw81qxCB"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "output_dir = f'./summary-training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4swN5p63lszx",
   "metadata": {
    "id": "4swN5p63lszx"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    num_train_epochs=2, #entire dataset will be trained on twice\n",
    "    # warmup_steps=1, # gradually increases learning rate from 0 to alpha in <warmp_steps> steps. Currently not useful\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    # max_steps=1000,  # can override num.epochs\n",
    "    learning_rate=1e-5,\n",
    "    optim=\"paged_adamw_8bit\", #optimiser used for gradient descent\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100, # prints the loss every 100 steps\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500, # Saves the model every 500 steps\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\",\n",
    "    overwrite_output_dir = 'True',\n",
    "    group_by_length=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8FuMTmsamCfw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "id": "8FuMTmsamCfw",
    "outputId": "29a0b232-32b9-465d-868e-ccacf59f0d2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2800' max='2800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2800/2800 07:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.519000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2800, training_loss=0.0677345957128065, metrics={'train_runtime': 471.7877, 'train_samples_per_second': 23.739, 'train_steps_per_second': 5.935, 'total_flos': 437437839283200.0, 'train_loss': 0.0677345957128065, 'epoch': 2.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VWVbmdZDBswe",
   "metadata": {
    "id": "VWVbmdZDBswe"
   },
   "source": [
    "## ***NOTE***\n",
    "\n",
    "- Loss is much less than it should be because of Model Over-Fitting.\n",
    "\n",
    "- This can be avoided by a larger dataset with more diverse examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S0p4EuJR_HZH",
   "metadata": {
    "id": "S0p4EuJR_HZH"
   },
   "source": [
    "### After training, load the model from directroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IhjgYUKyv7OC",
   "metadata": {
    "id": "IhjgYUKyv7OC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\ameht\\AppData\\Local\\Temp\\ipykernel_3428\\1783231278.py:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  model_path = \"summary-training-1748945582\\checkpoint-2800\"\n"
     ]
    }
   ],
   "source": [
    "model_path = \"summary-training\\checkpoint-2800\"\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RLX6FiyK_OiN",
   "metadata": {
    "id": "RLX6FiyK_OiN"
   },
   "source": [
    "We require the tokenizer used to tokenize the input text and feed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "Wj1WYWzpv88u",
   "metadata": {
    "id": "Wj1WYWzpv88u"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1opEujxW_bW8",
   "metadata": {
    "id": "1opEujxW_bW8"
   },
   "source": [
    "#### Testing on a random entry from test dataset\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0qAFyHnlwUjO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "0qAFyHnlwUjO",
    "outputId": "65ebe1ed-b7e1-441b-864d-decadda69ba0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>Re-intermediate e-business bandwidth. Fix bugs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>Monitor server metrics with Prometheus: Monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>Monitor server metrics with Prometheus: Monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Fix CSS styling issues for mobile view: Fix CS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4350</th>\n",
       "      <td>Normalize database schema: Normalize database ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>Set up cloudwatch alarms for EC2 instances: Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>Implement RESTful APIs with Node.js: Implement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>Add indexes to frequently queried columns: Add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Refactor frontend state management: Refactor f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336</th>\n",
       "      <td>Add indexes to frequently queried columns: Add...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description\n",
       "6500  Re-intermediate e-business bandwidth. Fix bugs...\n",
       "2944  Monitor server metrics with Prometheus: Monito...\n",
       "2024  Monitor server metrics with Prometheus: Monito...\n",
       "263   Fix CSS styling issues for mobile view: Fix CS...\n",
       "4350  Normalize database schema: Normalize database ...\n",
       "...                                                 ...\n",
       "3484  Set up cloudwatch alarms for EC2 instances: Se...\n",
       "1860  Implement RESTful APIs with Node.js: Implement...\n",
       "4974  Add indexes to frequently queried columns: Add...\n",
       "387   Refactor frontend state management: Refactor f...\n",
       "4336  Add indexes to frequently queried columns: Add...\n",
       "\n",
       "[1400 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = list(X_test['description'])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "XID7jhCqxe-V",
   "metadata": {
    "id": "XID7jhCqxe-V"
   },
   "outputs": [],
   "source": [
    "text = input[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "mCgZn8l9wemK",
   "metadata": {
    "id": "mCgZn8l9wemK"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5C4eHAM9wrfu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5C4eHAM9wrfu",
    "outputId": "a23092c5-217e-4674-b171-6ade95f6fec8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 45647,  2072,  8503, 47404,    35, 26411,  2072,  8503, 47404,\n",
       "             4, 28688,  2072, 41614, 22680,    13,   819,     4, 38141,   275,\n",
       "          3464,    32,  1432,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenized input string\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "T7XK9tyiw5oi",
   "metadata": {
    "id": "T7XK9tyiw5oi"
   },
   "outputs": [],
   "source": [
    "# Code to get models output\n",
    "import torch\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = torch.argmax(logits, dim=1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "NoId7GrwxII_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NoId7GrwxII_",
    "outputId": "f9507a46-73af-4625-9261-5806dd8c3fed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted role: DatabaseDesignEngineer\n"
     ]
    }
   ],
   "source": [
    "predicted_role = IndexToRole[predicted_class_id]\n",
    "print(\"Predicted role:\", predicted_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "QaBdZ1bL6YTJ",
   "metadata": {
    "id": "QaBdZ1bL6YTJ"
   },
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class_id = torch.argmax(logits, dim=1).item()\n",
    "        predicted_role = IndexToRole[predicted_class_id]\n",
    "        # print(\"Predicted Role\", predicted_role)\n",
    "        return predicted_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_hJsaYmz_sQ9",
   "metadata": {
    "id": "_hJsaYmz_sQ9"
   },
   "source": [
    "Testing the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "yPpCbazUxLsb",
   "metadata": {
    "id": "yPpCbazUxLsb"
   },
   "outputs": [],
   "source": [
    "def test_metric(model, X_test, y_test, tokenizer):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import torch\n",
    "    predictions = []\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    for text in X_test[\"description\"]:\n",
    "        predicted_role = predict(text, model, tokenizer)\n",
    "        predictions.append(predicted_role)\n",
    "\n",
    "    return [predictions, accuracy_score(y_test, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00k30IfjyvPr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00k30IfjyvPr",
    "outputId": "78915982-9579-4b0f-ff51-48293771a793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "# test_metric(model, X_test, y_test)\n",
    "predictions, score = test_metric(model, X_test, y_test, tokenizer)\n",
    "# print(predictions)\n",
    "print(\"accuracy : \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xrFj-fZpIxey",
   "metadata": {
    "id": "xrFj-fZpIxey"
   },
   "source": [
    "(Again, overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "wRW7h_cN5aRz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wRW7h_cN5aRz",
    "outputId": "0c30175a-a252-4311-d735-30279f1a2e18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DatabaseDesignEngineer'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "    Design a database schema to store user and admin data\n",
    "\"\"\"\n",
    "predict(text, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2794e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
